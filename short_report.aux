\relax 
\citation{wysoski2008fast}
\citation{canny1986computational}
\citation{toygar2004multiple}
\citation{wei2006robust}
\citation{lowe2004distinctive}
\citation{bay2008speeded}
\citation{riesenhuber1999hierarchical}
\citation{dicarlo2012does}
\citation{fabre1998rapid}
\citation{keysers2001speed}
\citation{dicarlo2007untangling}
\citation{lenero20113}
\citation{furber2014spinnaker}
\citation{felleman1991distributed}
\citation{dicarlo2012does}
\citation{dicarlo2012does}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}What Is Object Recognition?}{1}}
\newlabel{sec:aim}{{\unhbox \voidb@x \hbox {I-A}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Why Is It Important?}{1}}
\newlabel{sec:imp}{{\unhbox \voidb@x \hbox {I-B}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}How to Mimic The Brain?}{1}}
\newlabel{sec:brn}{{\unhbox \voidb@x \hbox {I-C}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Biological Aspects}{1}}
\newlabel{sec:bio}{{II}{1}}
\citation{hubel1959receptive}
\citation{anzai2007neurons}
\citation{daniel2009whither}
\citation{qiu2005figure}
\citation{dean1976effects}
\citation{tanaka1991coding}
\citation{gross2008single}
\citation{schwartz1983shape}
\citation{sary1993cue}
\citation{dicarlo2012does}
\citation{dicarlo2012does}
\citation{zoccolan2007trade}
\citation{desimone1984stimulus}
\citation{desimone1984stimulus}
\citation{hung2005fast}
\citation{majaj2012unified}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The ventral visual pathway and abstraction layers\nobreakspace  {}\cite  {dicarlo2012does}. \relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:Ventral}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}The ventral visual pathway}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Object Representation in IT}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  IT single-neuron properties and their relationship to population performance\nobreakspace  {}\cite  {dicarlo2012does}. \relax }}{2}}
\newlabel{Fig:IT}{{2}{2}}
\citation{hung2005fast}
\citation{brincat2006dynamic}
\citation{dicarlo2012does}
\citation{delbruck2008frame}
\citation{6252490}
\citation{galluppi2012real}
\citation{lazzaro1995multi}
\citation{lenero20113}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Hierarchical Feed-forward Organisation }{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Preliminary Work}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Platform}{3}}
\newlabel{fig:SysOverViewa}{{3a}{3}}
\newlabel{sub@fig:SysOverViewa}{{a}{3}}
\newlabel{fig:SysOverViewb}{{3b}{3}}
\newlabel{sub@fig:SysOverViewb}{{b}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces System overview of the object recognition platform. \relax }}{3}}
\newlabel{fig:SysOverView}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}CNN Nodels}{3}}
\citation{lecun1998gradient}
\citation{la2008response}
\citation{burkitt2006review}
\citation{siegert1951first}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Model 1. The retina input is convolved with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The templates are considered as convolution kernels in the last layer. The WTA circuit can be used as an option to show the template matching result more clearly. \relax }}{4}}
\newlabel{fig:model1}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Templates of the five postures: `Fist',`Index Finger', `Victory Sign', `Full Hand' and `Thumb up'.\relax }}{4}}
\newlabel{fig:template}{{5}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Model 2. The retina input convolves with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The following tracking layer finds the most active area of some fixed size, moves the posture to the centre and pushes the image to the trained MLP. The winner-take-all (WTA) layer can be used as an option to show the template matching result more clearly.\relax }}{4}}
\newlabel{fig:model2}{{6}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Moving from Perceptrons to Spiking Neurons}{4}}
\newlabel{equ:lif}{{1}{4}}
\newlabel{equ:consI}{{2}{4}}
\newlabel{equ:sde}{{3}{4}}
\newlabel{equ:ou}{{4}{4}}
\newlabel{equ:sgt}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Experiments}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Real-time neural responses of two experiments on SpiNNaker with time to recorded postures. These two experiments only differ in input resolution. Every point represents the over all number of spikes of a specific population (different colour) in a `frame'. First two plots are for a sample frame of 30\nobreakspace  {}ms; the latter are for a frame of 300\nobreakspace  {}ms. \relax }}{5}}
\newlabel{fig:spikerec}{{7}{5}}
\newlabel{fig:ssa}{{8a}{5}}
\newlabel{sub@fig:ssa}{{a}{5}}
\newlabel{fig:rec0}{{8b}{5}}
\newlabel{sub@fig:rec0}{{b}{5}}
\newlabel{fig:rec1}{{8c}{5}}
\newlabel{sub@fig:rec1}{{c}{5}}
\newlabel{fig:rec5}{{8e}{5}}
\newlabel{sub@fig:rec5}{{e}{5}}
\newlabel{fig:rect}{{8f}{5}}
\newlabel{sub@fig:rect}{{f}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Spikes captured during the live recognition of the recorded retinal input with the resolution of 128$\times $128. \relax }}{5}}
\newlabel{fig:rps}{{8}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Future Work}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces 3D representation of the research plan on the transformation-invariant object recognition system. Three milestones are pointed out indicating the expected targets of the object recognition networks. \relax }}{5}}
\newlabel{Fig:3Dplan}{{9}{5}}
\citation{hegde2004temporal}
\citation{zoccolan2007trade}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Gantt chart of the work flow for the first milestone. The main research works are listed on the left. \relax }}{6}}
\newlabel{Fig:gantt}{{10}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Invariant Object Recognition}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}1}Position Invariance}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}2}Scale Invariance}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}3}View Invariance}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Modelling the Ventral Visual Pathway}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Size Scaling}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Integration}{6}}
\bibdata{refs}
\bibcite{wysoski2008fast}{1}
\bibcite{canny1986computational}{2}
\bibcite{toygar2004multiple}{3}
\bibcite{wei2006robust}{4}
\bibcite{lowe2004distinctive}{5}
\bibcite{bay2008speeded}{6}
\bibcite{riesenhuber1999hierarchical}{7}
\bibcite{dicarlo2012does}{8}
\bibcite{fabre1998rapid}{9}
\bibcite{keysers2001speed}{10}
\bibcite{dicarlo2007untangling}{11}
\bibcite{lenero20113}{12}
\bibcite{furber2014spinnaker}{13}
\bibcite{felleman1991distributed}{14}
\bibcite{hubel1959receptive}{15}
\bibcite{anzai2007neurons}{16}
\bibcite{daniel2009whither}{17}
\bibcite{qiu2005figure}{18}
\bibcite{dean1976effects}{19}
\bibcite{tanaka1991coding}{20}
\bibcite{gross2008single}{21}
\bibcite{schwartz1983shape}{22}
\bibcite{sary1993cue}{23}
\bibcite{zoccolan2007trade}{24}
\bibcite{desimone1984stimulus}{25}
\bibcite{hung2005fast}{26}
\bibcite{majaj2012unified}{27}
\bibcite{brincat2006dynamic}{28}
\bibcite{delbruck2008frame}{29}
\bibcite{6252490}{30}
\bibcite{galluppi2012real}{31}
\bibcite{lazzaro1995multi}{32}
\bibcite{lecun1998gradient}{33}
\bibcite{la2008response}{34}
\bibcite{burkitt2006review}{35}
\bibcite{siegert1951first}{36}
\bibcite{hegde2004temporal}{37}
\bibstyle{ieeetr}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-E}}Tuning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-F}}Benchmarking Performance}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-F}1}Building a Dataset}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-F}2}Testing/Comparing}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
